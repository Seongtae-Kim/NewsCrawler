{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from lxml import etree as ET\n",
    "from lxml.builder import E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contemporary Chosun Crawler\n",
    "조선일보 2012, 2013, 2015, 2016, 2017년도 기사를 크롤링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기 y_xxxx는 시작 날짜이고 시작 날짜부터 당해 12월 31일까지의 일수를 period에 입력하면 됩니다.\n",
    "\n",
    "y_2012 = date.fromisoformat('2012-02-07')\n",
    "y_2013 = date.fromisoformat('2013-01-22')\n",
    "y_2015 = date.fromisoformat('2015-01-01')\n",
    "y_2016 = date.fromisoformat('2016-01-19')\n",
    "y_2017 = date.fromisoformat('2017-01-15')\n",
    "datelist2012 = pd.date_range(y_2012, periods=329) # from 2012-01-14 to 2012-12-31\n",
    "datelist2013 = pd.date_range(y_2013, periods=344) # from 2013-01-01 to 2013-12-31\n",
    "datelist2015 = pd.date_range(y_2015, periods=365) # from 2015-01-01 to 2015-12-31\n",
    "datelist2016 = pd.date_range(y_2016, periods=346) # from 2016-01-01 to 2016-12-31 (leap year)\n",
    "datelist2017 = pd.date_range(y_2017, periods=351) # from 2017-01-01 to 2017-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "# 크롤링하고 싶은 연도를 입력하면 됩니다.\n",
    "datelist = [] # 2012\n",
    "for date in datelist2012: # 여기 연도를 바꾸세요!\n",
    "    d = str(date).split(\" \")[0]\n",
    "    d = d.replace(\"-\", \"\")\n",
    "    datelist.append(d)\n",
    "print(len(datelist)) # 1827 days to crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_sample = \"http://news.chosun.com/svc/list_in/list.html?indate=\"\n",
    "\n",
    "urls=[]\n",
    "\n",
    "for date in datelist:\n",
    "    urls.append(url_sample+date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    title=\"\"\n",
    "    category=\"\"\n",
    "    paragraph=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_writer(article, date):\n",
    "    name = date + \"_\" + article.category + \"_\" + article.title\n",
    "    txt = \"\"\n",
    "    txt = txt + article.paragraph\n",
    "    name = name.replace(\"/\", \" \")\n",
    "    \n",
    "    with open(\"./output/\"+ name +\".txt\", \"w\") as text_file:\n",
    "        text_file.write(txt)\n",
    "\n",
    "def xml_writer(article, date):\n",
    "    name = date + \"_\" + article.category + \"_\" + article.title\n",
    "    name = name.replace(\"/\", \" \")\n",
    "    title = E(\"title\", article.title)\n",
    "    category = E(\"category\", article.category)\n",
    "    paragraph = E(\"paragraph\", article.paragraph)\n",
    "    article_xml = E(\"article\", category, title, paragraph)\n",
    "    \n",
    "    declaration = \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "    <!DOCTYPE articles SYSTEM \"articles.dtd\">\n",
    "    \"\"\"\n",
    "    dec_byte = str.encode(declaration)\n",
    "    with open(\"./output/\"+ name +\".xml\", \"wb\") as f:\n",
    "        f.write(dec_byte)\n",
    "        f.write(ET.tostring(article_xml, xml_declaration=False, encoding=\"utf-8\", pretty_print=True))\n",
    "        \n",
    "def article_extractor(article_urls, article_list, date):\n",
    "    for article in article_urls:\n",
    "        a = Article()\n",
    "        browser.get(article)\n",
    "        a.title = browser.find_elements_by_id(\"news_title_text_id\")[0].text\n",
    "        a.category = browser.find_elements_by_id(\"news_cat_trig_id\")[0].text\n",
    "        a.paragraph = browser.find_elements_by_class_name(\"par\")[0].text\n",
    "        text_writer(a, date)\n",
    "        xml_writer(a, date)\n",
    "        \n",
    "        #article_list.append(a)\n",
    "        print(date, len(article_list),\"번째 기사: '\", a.title, \"'완료\")\n",
    "\n",
    "def list_extractor(page_url, article_list, date):\n",
    "    articles = browser.find_elements_by_class_name(\"list_item\")\n",
    "    article_urls=[]\n",
    "    for article in articles:\n",
    "        if len(article.find_elements_by_class_name(\"author\")) != 0:\n",
    "            author = article.find_elements_by_class_name(\"author\")[0]\n",
    "            if len(author.text) >= 5:\n",
    "                if author.text[:5] == \"스포츠조선\": # Excluding Sports Articles\n",
    "                    pass\n",
    "                else:\n",
    "                    article_urls.append(article.find_elements_by_tag_name(\"a\")[0].get_attribute(\"href\"))\n",
    "            else:\n",
    "                article_urls.append(article.find_elements_by_tag_name(\"a\")[0].get_attribute(\"href\"))\n",
    "    article_extractor(article_urls, article_list, date)\n",
    "\n",
    "def page_browser(url, article_list): # browsing pages of that date\n",
    "    i=1 # page index\n",
    "    while len(browser.find_elements_by_class_name(\"list_item\")) >= 1:\n",
    "        if i == 1:\n",
    "            page = \"&pn=\" + str(i)\n",
    "            date = url[-8:]\n",
    "            page_url = url + page\n",
    "            browser.get(page_url)\n",
    "        list_extractor(page_url, article_list, date)\n",
    "        i += 1\n",
    "        page = \"&pn=\" + str(i)\n",
    "        page_url = url + page\n",
    "        browser.get(page_url)\n",
    "        \n",
    "def contemporary_chosun_crawler(urls):\n",
    "    article_list=[]\n",
    "    for url in urls:\n",
    "        browser.get(url)\n",
    "        page_browser(url, article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120207 0 번째 기사: ' [태평로] 부자 세금만으론 복지 흉내밖에 못 낸다 '완료\n",
      "20120207 0 번째 기사: ' [우정아의 아트 스토리] [50] 잭슨 폴락, '넘버 1' '완료\n",
      "20120207 0 번째 기사: ' [만물상] 한류 수출 '완료\n",
      "20120207 0 번째 기사: ' [만물상] 한류 수출 '완료\n",
      "20120207 0 번째 기사: ' [시론] 장시간 노동에 길든 한국인들 '완료\n",
      "20120207 0 번째 기사: ' [특파원 칼럼] 롬니의 발목 잡는 富 '완료\n",
      "20120207 0 번째 기사: ' [박두식 칼럼] 뒤집기의 達人들 '완료\n",
      "20120207 0 번째 기사: ' [ESSAY] 내 친구의 詩 '완료\n",
      "20120207 0 번째 기사: ' [편집자에게] 21세기의 새로운 외교 전쟁 '공공 외교' '완료\n",
      "20120207 0 번째 기사: ' [편집자에게] 준비된 교사를 위한 인턴교사제 도입을 '완료\n",
      "20120207 0 번째 기사: ' [편집자에게] 아이를 키우는 데 공짜는 없다 '완료\n",
      "20120207 0 번째 기사: ' 가출 거부한 친구 담뱃불로 지진 여중생 '완료\n",
      "20120207 0 번째 기사: ' 광주 장애인 복지시설 성폭행 의혹 '완료\n",
      "20120207 0 번째 기사: ' 50대 경찰관의 자살 '완료\n",
      "20120207 0 번째 기사: ' 영화 개봉실적에 따라 개발비 지원 '완료\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: Browsing context has been discarded\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1f2fd6240099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontemporary_chosun_crawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-600aef57efef>\u001b[0m in \u001b[0;36mcontemporary_chosun_crawler\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mpage_browser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-600aef57efef>\u001b[0m in \u001b[0;36mpage_browser\u001b[0;34m(url, article_list)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpage_browser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# browsing pages of that date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# page index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_item\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"&pn=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_elements_by_class_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \"\"\"\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcss_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         return self.execute(Command.FIND_ELEMENTS, {\n\u001b[1;32m   1006\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             'value': value})['value'] or []\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: Browsing context has been discarded\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Firefox()\n",
    "contemporary_chosun_crawler(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
